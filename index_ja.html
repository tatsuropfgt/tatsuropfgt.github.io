<!DOCTYPE html>
<html lang="ja">
<head>
  <meta charset="UTF-8" />
  <title>稲葉 達郎 (Tatsuro Inaba)</title>
  <link rel="stylesheet" href="style.css" />
</head>
<body>
  <div class="container">
    <h1 class="header-with-link">
      稲葉 達郎 (Tatsuro Inaba)
      <span style="font-size: 0.5em;">[<a href="index.html" class="lang-link">English</a>]</span>
    </h1>

    <section class="intro">
      <img src="figs/img_profile.jpg" alt="Tatsuro Inaba" width="200" />
      <div class="intro-text">
        <p>
          東北大学 <a href="https://www.nlp.ecei.tohoku.ac.jp/">Tohoku NLP Group</a> 博士課程1年の稲葉達郎です。
          国立情報学研究所<a href="https://llmc.nii.ac.jp/">大規模言語モデル研究開発センター</a>でリサーチアシスタントも務めています。
          音楽情報処理と自然言語処理に興味があり、特に音楽モデル/言語モデルの学習ダイナミクスに興味があります。
        </p>
        <ul>
          <li>Email: tatsuro.pianooo[at]gmail.com</li>
          <li><a href="https://x.com/Ina_pfgt">Twitter(X)</a></li>
          <li><a href="https://scholar.google.com/citations?user=nHLiIasAAAAJ&hl=en">Google Scholar</a></li>
          <li><a href="https://github.com/tatsuropfgt">GitHub</a></li>
        </ul>
      </div>
    </section>
    
    <section class="news">
      <h2>ニュース</h2>
      <ul>
        <li>2025/6: 九州大学で講演とチュートリアルを行いました。 [<a href="documents/20250602_KyushuUniv.pdf">talk slides</a>]</li>
        <li>2025/4: <a href="https://www.nlp.ecei.tohoku.ac.jp/">東北大学 NLP グループ</a>に博士課程学生として編入学しました。</li>
        <li>2025/3: 主著の preprint <em>"How LLMs Learn: Tracing Internal Representations with Sparse Autoencoders."</em> を arXiv で公開しました。 [<a href="https://arxiv.org/abs/2503.06394">arXiv</a>]</li> 
      </ul>
    </section>

    <section class="career">
      <h2>経歴</h2>
        <h3>学歴</h3>
        <ul>
          <li>2025/4-現在: 東北大学大学院情報科学研究科 博士後期課程</li>
            <ul><li>指導教員: <a href=https://kentaro-inui.github.io>乾健太郎</a>、<a href=https://keisuke-sakaguchi.github.io>坂口 慶祐</a></li></ul>
          <li>2023/4-2025/3: 京都大学大学院情報学研究科 修士課程</li>
            <ul><li>指導教員: <a href="https://researchmap.jp/k.yoshii?lang=en">吉井和佳</a></li></ul>
          <li>2019/4-2023/3: 京都大学工学部電気電子工学科 学士課程</li>
            <ul><li>指導教員: <a href="https://nlp.ist.i.kyoto-u.ac.jp/member/kuro/index.html">黒橋貞夫</a></li></ul>
        </ul>

        <h3>職歴</h3>
        <ul>
          <li>2025/4-現在: 日本学術振興会特別研究員（DC1）, 東北大学</li>
          <li>2024/12-現在: リサーチアシスタント, 国立情報学研究所大規模言語モデル研究開発センター </li>
          <li>2024/1-2024/2: Visiting Student, Mohamed Bin Zayed University of Artificial Intelligence (MBZUAI) Visiting Student [<a href=https://zenn.dev/tatsuro_pfgt/articles/14b949482b436f>blog</a>]</li>
          <li>2023/11-2024/11: リサーチアシスタント, Kyoto University.</li>
          <li>2023/9-2023/10: 開発インターン, Recruit Co., Ltd.</li>
          <li>2023/8-2023/9: リサーチインターン, Preferred Networks, Inc. [<a href=https://tech.preferred.jp/ja/blog/knowledge-distillation-using-intermediate-representations>blog</a>]</li>
          <li>2022/11-2023/7: リサーチエンジニア, DATAGRID Inc.</li>
        </ul>
    </section>

    <section class="grant">
      <h2>奨学金・受賞</h2>
      <ul>
          <li>2025/4-現在: <a href="https://www.jsps.go.jp/english/e-pd/">日本学術振興会特別研究員（DC1）</a> (708/4959=14.3%)、「音楽知識を有する記号音楽と言語のマルチモーダルモデルの作成」</li>
          <li>2024/8: <a href="https://www.ipsj.or.jp/award/mus-award3.html">学生奨励賞</a>, 第141回音楽情報科学研究発表会 (SIGMUS).</li>
          <li>2023/8: <a href="https://yans.anlp.jp/entry/award">奨励賞</a> (20/139=14.4%), NLP若手の会 (YANS) 第18回シンポジウム.</li>
          <li>2023/3: <a href="https://www.anlp.jp/nlp2023/award.html">優秀賞</a> (13/579=2.2%), 言語処理学会第29回年次大会.</li>
      </ul>
    </section>

    <section class="publications">
      <h2>出版物</h2>
        <h3>Preprints</h3>
        <ul>
          <li>
            Ryosuke Takahashi, <u>Tatsuro Inaba</u>, Kentaro Inui, and Benjamin Heinzerling.<br>
            "TopK Language Models."<br>
            [<a href="https://arxiv.org/abs/2506.21468">arXiv</a>] 
          </li>
          <li>
            <u>Tatsuro Inaba</u>, Kentaro Inui, Yusuke Miyao, Yohei Oseki, Benjamin Heinzerling, and Yu Takagi.<br>
            "How LLMs Learn: Tracing Internal Representations with Sparse Autoencoders."<br>
            [<a href="https://arxiv.org/abs/2503.06394">arXiv</a>] 
          </li>
        </ul>
        <h3>国際会議（査読あり）</h3>
        <ul>
          <li>
            Go Kamoda, Benjamin Heinzerling, <u>Tatsuro Inaba</u>, Keito Kudo, Keisuke Sakaguchi, and Kentaro Inui.<br>
            "Weight-based Analysis of Detokenization in Language Models: Understanding the First Stage of Inference Without Inference."<br>
            The 2025 Annual Conference of the Nations of the Americas Chapter of the Association for Computational Linguistics (NAACL 2025 findings)<br>
            [<a href="https://arxiv.org/abs/2503.06394">arXiv</a>]
          </li>
          <li>
            <u>Tatsuro Inaba</u>, Kazuyoshi Yoshii, and Eita Nakamura.<br>
            "On the Importance of Time and Pitch Relativity for Transformer-Based Symbolic Music Generation."<br>
            The 16th Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA 2024)<br>
            [<a href="https://ieeexplore.ieee.org/document/10849230">paper</a>]
          </li>
          <li>
            <u>Tatsuro Inaba</u>, Hirokazu Kiyomaru, Fei Cheng, and Sadao Kurohashi.<br>
            "MultiTool-CoT: GPT-3 Can Use Multiple External Tools with Chain of Thought Prompting"<br>
            The 61st Annual Meeting of the Association for Computational Linguistics (ACL 2023 main)<br>
            [<a href="https://github.com/tatsuropfgt/MultiTool-CoT">code</a>, <a href="https://arxiv.org/abs/2305.16896">arXiv</a>, <a href="documents/ACL2023_poster.pdf">poster</a>]
          </li>
        </ul>
        <h3>国内会議（査読なし）</h3>
        <ul>
          <li>
            <u>稲葉 達郎</u>, 乾 健太郎, 宮尾 祐介, 大関 洋平, Benjamin Heinzerling, 高木 優.<br>
            「スパースオートエンコーダーを用いた大規模言語モデルのチェックポイント横断分析」<br>
            言語処理学会第31回年次大会．2025.<br>
            [<a href="https://www.anlp.jp/proceedings/annual_meeting/2025/pdf_dir/A6-1.pdf">paper</a>]
          </li>
          <li>
            鴨田 豪, Benjamin Heinzerling, <u>稲葉 達郎</u>, 工藤 慧音, 坂口 慶祐, 乾 健太郎.<br>
            「言語モデルのパラメータから探るDetokenizationメカニズム」<br>
            言語処理学会第31回年次大会．2025.<br>
            [<a href="https://www.anlp.jp/proceedings/annual_meeting/2025/pdf_dir/P2-9.pdf">paper</a>]
          </li>
          <li>
            <u>稲葉 達郎</u>, 吉井 和佳, 中村 栄太.<br>
            「音楽生成における時間と音高相対性の重要性」<br>
            第141回音楽情報科学研究発表会 (SIGMUS)．2024.<br>
            [<a href="http://id.nii.ac.jp/1001/00238077/">paper</a>]
          </li>
          <li>
            <u>稲葉 達郎</u>, 清丸 寛一, Fei Cheng, 黒橋 貞夫.<br>
            「大規模言語モデルに基づく複数の外部ツールを利用した推論フレームワーク」<br>
            言語処理学会第29回年次大会．2023.<br>
            [<a href="https://www.anlp.jp/proceedings/annual_meeting/2023/pdf_dir/Q8-10.pdf">paper</a>, <a href="documents/NLP2023_poster.pdf">poster</a>]
          </li>
          <li>
            <u>稲葉 達郎</u>, 藤井 拓郎, 小原 涼馬, 柴田 幸輝.<br>
            「三言語モデル寄れば文殊の知恵を」<br>
            NLP若手の会 (YANS) 第18回シンポジウム, 2023.<br>
            [<a href="documents/YANS2023_poster.pdf">poster</a>]
          </li>
        </ul>
    </section>
    <section class="talks">
      <h2>招待公演・学会活動等</h2>
        <ul>
          <li>06/2025: 講演とチュートリアル (Pytorch/Transformer/Music Generation), 九州大学 [<a href="documents/20250602_KyushuUniv.pdf">talk slides</a>]</li>
          <li>03/2025: 講演, 東北大学 [<a href="documents/20250305_TohokuUniv.pdf">slides</a>]</li>
          <li>08/2024: 論文紹介．第16回最先端NLP勉強会 [<a href="documents/SNLP2024_inaba_Language_Specific_Neurons.pdf">slides</a>]</li>
          <li>09/2023: 学会記事．「大規模言語モデルに基づく複数の外部ツールを利用した推論フレームワーク」の研究．自然言語処理 30巻 3号 p.1100-1104．[<a href=https://www.jstage.jst.go.jp/article/jnlp/30/3/30_1100/_article/-char/ja>paper</a>]</li>
          <li>08/2023: 論文紹介．第15回最先端NLP勉強会 [<a href=documents/SNLP2023_inaba_Backpack_Language_Models.pdf>slides</a>]</li>
    <footer>
      <p>&copy; Tatsuro Inaba June 2025</p>
    </footer>
  </div>
</body>
</html>
