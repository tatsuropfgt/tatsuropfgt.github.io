<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="format-detection" content="telephone=no" />
  <meta name="google-site-verification" content="HfLE5PnfeVA6wIK8FI-W1GNLg87p7_QoSrGYfUvY5Vs" />
  <title>Tatsuro Inaba （稲葉達郎）</title>
  <link rel="stylesheet" href="style.css" />
</head>
<body>
  <div class="container">
    <h1>Tatsuro Inaba (稲葉達郎)</h1>

    <section class="intro">
      <img src="figs/img_profile.jpg" alt="Tatsuro Inaba" width="200" />
      <div class="intro-text">
        <p>
          Tatsuro Inaba is a first-year Ph.D. student in <a href="https://www.nlp.ecei.tohoku.ac.jp/">Tohoku NLP Group</a> at Tohoku University. 
          He also serves as a research assistant at <a href="https://llmc.nii.ac.jp/en/">Research and Development Center for Large Language Models</a>, National Institute of Informatics. 
          His research interests lie at the intersection of language and music, with a particular focus on the internal mechanisms of Neural Networks.
        </p>
        <ul>
          <li>Email: tatsuro.pianooo[at]gmail.com</li>
          <li><a href="https://x.com/Ina_pfgt">Twitter(X)</a></li>
          <li><a href="https://scholar.google.com/citations?user=nHLiIasAAAAJ&hl=en">Google Scholar</a></li>
          <li><a href="https://github.com/tatsuropfgt">GitHub</a></li>
        </ul>
      </div>
    </section>
    
    <section class="news">
      <h2>News</h2>
      <ul>
        <li>04/2025: Joined <a href="https://www.nlp.ecei.tohoku.ac.jp/">Tohoku NLP Group</a> as a Ph.D. student.</li>
        <li>03/2025: Gave a talk at Tohoku NLP Group. [<a href="documents/20250305_TohokuUniv.pdf">slides</a>]
        <li>03/2025: First-author preprint <em>"How LLMs Learn: Tracing Internal Representations with Sparse Autoencoders."</em> posted on arXiv. [<a href="https://arxiv.org/abs/2503.06394">arXiv</a>].</li> 
      </ul>
    </section>

    <section class="career">
      <h2>Career</h2>
        <h3>Education</h3>
        <ul>
          <li>04/2025-present: Ph.D. student, Graduate School of Information Sciences, Tohoku University.</li>
          <li>04/2023-03/2025: Master student, Graduate School of Informatics, Kyoto University.</li>
          <li>04/2019-03/2023: Bachelor student, Undergraduate School of Electrical and Electronic Engineering, Kyoto University.</li>
        </ul>

        <h3>Experience</h3>
        <ul>
          <li>12/2024-present: Research Assistant, Research and Development Center for Large Language Models, National Institute of Informatics.</li>
          <li>01/2024-02/2024: Visiting Student, Mohamed Bin Zayed University of Artificial Intelligence (MBZUAI).</li>
          <li>11/2023-11/2024: Research Assistant, Kyoto University.</li>
          <li>09/2023-10/2023: Machine Learning Engineer, Internship, Recruit Co., Ltd.</li> 
          <li>08/2023-09/2023: Researcher, Internship, Preferred Networks, Inc.</li>
          <li>11/2022-07/2023: Reseach Engineer, Part-time, DATAGRID Inc.</li>
        </ul>
    </section>

    <section class="grant">
      <h2>Grants/Awards</h2>
      <ul>
          <li>04/2025-present: <a href="https://www.jsps.go.jp/english/e-pd/">Doctoral Course (DC1) Research Fellowship</a> (708/4959=14.3%), Japan Society for the Promotion of Science (JSPS). 「音楽知識を有する記号音楽と言語のマルチモーダルモデルの作成」</li>
          <li>08/2024: <a href="https://www.ipsj.or.jp/award/mus-award3.html">Student Encouragement Award</a>, 第141回音楽情報科学研究発表会 (SIGMUS).</li>
          <li>08/2023: <a href="https://yans.anlp.jp/entry/award">Encouragement Award</a> (20/139=14.4%), NLP若手の会 (YANS) 第18回シンポジウム.</li>
          <li>03/2023: <a href="https://www.anlp.jp/nlp2023/award.html">Outstanding Award</a> (13/579=2.2%), 言語処理学会第29回年次大会.</li>
      </ul>
    </section>

    <section class="publications">
      <h2>Publications</h2>
        <h3>Preprints</h3>
        <ul>
          <li>
            <u>Tatsuro Inaba</u>, Kentaro Inui, Yusuke Miyao, Yohei Oseki, Benjamin Heinzerling, and Yu Takagi.<br>
            "How LLMs Learn: Tracing Internal Representations with Sparse Autoencoders."<br>
            [<a href="https://arxiv.org/abs/2503.06394">arXiv</a>] 
          </li>
        </ul>
        <h3>Refereed Papers</h3>
        <ul>
          <li>
            Go Kamoda, Benjamin Heinzerling, <u>Tatsuro Inaba</u>, Keito Kudo, Keisuke Sakaguchi, and Kentaro Inui.<br>
            "Weight-based Analysis of Detokenization in Language Models: Understanding the First Stage of Inference Without Inference."<br>
            The 2025 Annual Conference of the Nations of the Americas Chapter of the Association for Computational Linguistics (NAACL 2025 findings)<br>
            [<a href="https://arxiv.org/abs/2503.06394">arXiv</a>]
          </li>
          <li>
            <u>Tatsuro Inaba</u>, Kazuyoshi Yoshii, and Eita Nakamura.<br>
            "On the Importance of Time and Pitch Relativity for Transformer-Based Symbolic Music Generation."<br>
            The 16th Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA 2024)<br>
            [<a href="https://ieeexplore.ieee.org/document/10849230">paper</a>]
          </li>
          <li>
            <u>Tatsuro Inaba</u>, Hirokazu Kiyomaru, Fei Cheng, and Sadao Kurohashi.<br>
            "MultiTool-CoT: GPT-3 Can Use Multiple External Tools with Chain of Thought Prompting"<br>
            The 61st Annual Meeting of the Association for Computational Linguistics (ACL 2023 main)<br>
            [<a href="https://github.com/tatsuropfgt/MultiTool-CoT">code</a>, <a href="https://arxiv.org/abs/2305.16896">arXiv</a>, <a href="documents/ACL2023_poster.pdf">poster</a>]
          </li>
        </ul>
        <h3>Domestic Conference (Japan)</h3>
        <ul>
          <li>
            <u>稲葉 達郎</u>, 乾 健太郎, 宮尾 祐介, 大関 洋平, Benjamin Heinzerling, 高木 優.<br>
            「スパースオートエンコーダーを用いた大規模言語モデルのチェックポイント横断分析」<br>
            言語処理学会第31回年次大会．2025.<br>
            [<a href="https://www.anlp.jp/proceedings/annual_meeting/2025/pdf_dir/A6-1.pdf">paper</a>]
          </li>
          <li>
            鴨田 豪, Benjamin Heinzerling, <u>稲葉 達郎</u>, 工藤 慧音, 坂口 慶祐, 乾 健太郎.<br>
            「言語モデルのパラメータから探るDetokenizationメカニズム」<br>
            言語処理学会第31回年次大会．2025.<br>
            [<a href="https://www.anlp.jp/proceedings/annual_meeting/2025/pdf_dir/P2-9.pdf">paper</a>]
          </li>
          <li>
            <u>稲葉 達郎</u>, 吉井 和佳, 中村 栄太.<br>
            「音楽生成における時間と音高相対性の重要性」<br>
            第141回音楽情報科学研究発表会 (SIGMUS)．2024.<br>
            [<a href="http://id.nii.ac.jp/1001/00238077/">paper</a>]
          </li>
          <li>
            <u>稲葉 達郎</u>, 清丸 寛一, Fei Cheng, 黒橋 貞夫.<br>
            「大規模言語モデルに基づく複数の外部ツールを利用した推論フレームワーク」<br>
            言語処理学会第29回年次大会．2023.<br>
            [<a href="https://www.anlp.jp/proceedings/annual_meeting/2023/pdf_dir/Q8-10.pdf">paper</a>, <a href="documents/NLP2023_poster.pdf">poster</a>]
          </li>
          <li>
            <u>稲葉 達郎</u>, 藤井 拓郎, 小原 涼馬, 柴田 幸輝.<br>
            「三言語モデル寄れば文殊の知恵を」<br>
            NLP若手の会 (YANS) 第18回シンポジウム, 2023.<br>
            [<a href="documents/YANS2023_poster.pdf">poster</a>]
          </li>
        </ul>
    </section>
    <section class="talks">
      <h2>Talks/Activities</h2>
        <ul>
          <li>03/2025: Talk at Tohoku NLP Group. [<a href="documents/20250305_TohokuUniv.pdf">slides</a>]</li>
          <li>08/2024: 論文紹介．第16回最先端NLP勉強会 [<a href="documents/SNLP2024_inaba_Language_Specific_Neurons.pdf">slides</a>]</li>
          <li>09/2023: 学会記事．「大規模言語モデルに基づく複数の外部ツールを利用した推論フレームワーク」の研究．自然言語処理 30巻 3号 p.1100-1104．[<a href=https://www.jstage.jst.go.jp/article/jnlp/30/3/30_1100/_article/-char/ja>paper</a>]</li>
          <li>08/2023: 論文紹介．第15回最先端NLP勉強会 [<a href=documents/SNLP2023_inaba_Backpack_Language_Models.pdf>slides</a>]</li>
    <footer>
      <p>&copy; Tatsuro Inaba Apr. 2025</p>
    </footer>
  </div>
</body>
</html>
